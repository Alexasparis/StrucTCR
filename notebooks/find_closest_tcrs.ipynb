{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "os.chdir(\"/Users/alexascunceparis/Desktop/BSC/immuno_project/TCRranker\")\n",
    "\n",
    "from find_contact_map import *\n",
    "from mapping import *\n",
    "from select_nr_set import *\n",
    "from extract_contacts import *\n",
    "\n",
    "seq_dict=parse_general_file('./structures_annotation/general.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_tcr_to_dataframe(df, alpha_seq, beta_seq, tcr_name):\n",
    "    \"\"\"\n",
    "    Adds TCR information to the DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The DataFrame to which TCR information will be added.\n",
    "    - alpha_seq (str): The TCR alpha chain sequence.\n",
    "    - beta_seq (str): The TCR beta chain sequence.\n",
    "    - tcr_name (str): Identifier for the input TCR.\n",
    "    \n",
    "    Returns:\n",
    "    - pd.DataFrame: Updated DataFrame with new TCR information added.\n",
    "    \"\"\"\n",
    "    # Generate the new pdb_id\n",
    "    pdb_id = f\"{tcr_name}\"\n",
    "\n",
    "    # Alpha chain\n",
    "    anarci_output_alpha = run_anarci(alpha_seq, \"D\")\n",
    "    cdr3_alpha, _ = parse_CDR3(anarci_output_alpha)\n",
    "    v_gene_alpha, j_gene_alpha = get_germlines(alpha_seq)\n",
    "    \n",
    "    # Beta chain\n",
    "    anarci_output_beta = run_anarci(beta_seq, \"E\")\n",
    "    cdr3_beta, _ = parse_CDR3(anarci_output_beta)\n",
    "    v_gene_beta, j_gene_beta = get_germlines(beta_seq)\n",
    "    \n",
    "    # New row as DataFrame\n",
    "    new_row = pd.DataFrame({\n",
    "        'pdb_id': [pdb_id],\n",
    "        'cdr3_a_aa': [cdr3_alpha],\n",
    "        'v_a_gene': [v_gene_alpha],\n",
    "        'j_a_gene': [j_gene_alpha],\n",
    "        'cdr3_b_aa': [cdr3_beta],\n",
    "        'v_b_gene': [v_gene_beta],\n",
    "        'j_b_gene': [j_gene_beta],\n",
    "        'count': [1]\n",
    "    })\n",
    "\n",
    "    # Add the new row to the DataFrame\n",
    "    df = pd.concat([df, new_row], ignore_index=True)\n",
    "       \n",
    "    return df\n",
    "\n",
    "\n",
    "def find_closest_tcr(df, alpha_seq, beta_seq, tcr_name):\n",
    "    \"\"\"\n",
    "    Finds the closest TCR to the given sequences.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The DataFrame containing existing TCR information.\n",
    "    - alpha_seq (str): The TCR alpha chain sequence of the new TCR.\n",
    "    - beta_seq (str): The TCR beta chain sequence of the new TCR.\n",
    "    - tcr_name (str): The TCR name for the new entry.\n",
    "\n",
    "    Returns:\n",
    "    - str: The pdb_id of the closest TCR, ensuring `tcr_name` and `pdb_id` don't match.\n",
    "    \"\"\"\n",
    "    # Add the new TCR to the DataFrame\n",
    "    df = add_tcr_to_dataframe(df, alpha_seq, beta_seq, tcr_name)\n",
    "\n",
    "    # Extract the last row as a DataFrame (which is the newly added TCR)\n",
    "    last_row = df.iloc[[-1]]\n",
    "\n",
    "    # List to store the global distances\n",
    "    results = []\n",
    "\n",
    "    # Construct the path to the database file\n",
    "    dir_path = os.getcwd()\n",
    "    db_file_path = os.path.join(dir_path, 'structures_annotation', 'alphabeta_gammadelta_db.tsv')\n",
    "\n",
    "    # Iterate over each row of the DataFrame except the last one\n",
    "    for end_row in range(len(df) - 1):\n",
    "        current_row = df.iloc[[end_row]]  # Current row as DataFrame\n",
    "        \n",
    "        # Check if the current pdb_id matches the new TCR name\n",
    "        current_pdb_id = current_row['pdb_id'].values[0]  # Assuming 'pdb_id' is the column name for pdb IDs\n",
    "        if current_pdb_id == tcr_name:\n",
    "            continue  # Skip if the current pdb_id matches the new TCR name\n",
    "\n",
    "        # Create TCRrep for the current row\n",
    "        tr_current = TCRrep(cell_df=current_row,\n",
    "                            organism='human', \n",
    "                            chains=['alpha', 'beta'], \n",
    "                            compute_distances=False,\n",
    "                            db_file=db_file_path)\n",
    "\n",
    "        # Create TCRrep for the last row (new TCR)\n",
    "        tr_last_row = TCRrep(cell_df=last_row, \n",
    "                             organism='human', \n",
    "                             chains=['alpha', 'beta'], \n",
    "                             compute_distances=False,\n",
    "                             db_file=db_file_path)\n",
    "\n",
    "        # Compute distances between the two TCRs\n",
    "        tr_current.compute_rect_distances(df=tr_last_row.clone_df, df2=tr_current.clone_df)\n",
    "\n",
    "        # Sum the alpha and beta chain distances to get global distance\n",
    "        global_distances = [tr_current.rw_alpha[0][i] + tr_current.rw_beta[0][i] for i in range(len(tr_current.rw_alpha[0]))]\n",
    "        \n",
    "        # Append the global distance for this row\n",
    "        results.append(global_distances)\n",
    "\n",
    "    # Check if we have valid results\n",
    "    if not results:\n",
    "        raise ValueError(\"No valid TCRs found for comparison.\")\n",
    "\n",
    "    # Flatten the results\n",
    "    flattened_results = [item[0] for item in results]\n",
    "\n",
    "    # Find the minimum global distance\n",
    "    min_value = min(flattened_results)\n",
    "\n",
    "    # Get all indices where the value is equal to the minimum value\n",
    "    min_indices = [index for index, value in enumerate(flattened_results) if value == min_value]\n",
    "\n",
    "    # Collect PDB IDs for the minimum distances\n",
    "    pdb_ids_with_min_distance = [df.iloc[index]['pdb_id'] for index in min_indices]\n",
    "\n",
    "    # Return the first matching pdb_id or handle ties\n",
    "    return pdb_ids_with_min_distance[0] if len(pdb_ids_with_min_distance) == 1 else pdb_ids_with_min_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract TCRs from PDB_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "# Path to the pdb_nr folder\n",
    "pdb_folder = \"./pdb_nr/\"\n",
    "\n",
    "# Open the CSV file for writing\n",
    "with open('pdb_sequences.csv', mode='w', newline='') as csv_file:\n",
    "    # Create a CSV writer\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    \n",
    "    # Write the header row\n",
    "    csv_writer.writerow(['tcr_id', 'alpha_seq', 'beta_seq'])\n",
    "\n",
    "    # Loop over each PDB file in the directory\n",
    "    for pdb_file in os.listdir(pdb_folder):\n",
    "        if pdb_file.endswith(\".pdb\"):\n",
    "            # Construct the full file path\n",
    "            pdb_file_path = os.path.join(pdb_folder, pdb_file)\n",
    "            \n",
    "            # Extract the PDB ID from the file name\n",
    "            pdb_id = pdb_file.split(\".\")[0]\n",
    "            \n",
    "            # Extract the sequences (adjust this function as per your actual logic)\n",
    "            alpha_seq, beta_seq, epitope = extract_specific_sequences(pdb_file_path, seq_dict)\n",
    "            \n",
    "            # Write the PDB ID, alpha sequence, and beta sequence to the CSV file\n",
    "            csv_writer.writerow([pdb_id, alpha_seq, beta_seq])\n",
    "\n",
    "print(\"CSV file written successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find similar TCRs for sequence data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closest TCR for 32145: 5tez\n",
      "Closest TCR for 1333: 2nx5\n",
      "Closest TCR for 31905: 5tez\n",
      "Closest TCR for 32308: ['4g9f', '4g8g']\n",
      "Closest TCR for 21404: 3vxm\n",
      "Closest TCR for 30362: 5d2n\n",
      "Closest TCR for 1037: 5d2l\n",
      "Closest TCR for 32953: 3tjh\n",
      "Closest TCR for 32560: 8i5d\n",
      "Closest TCR for 1199: 6bj2\n",
      "Closest TCR for 32448: 6rpa\n",
      "Closest TCR for 33472: ['7nmg', '7nme', '7nmf']\n",
      "Closest TCR for 31880: 7phr\n",
      "Closest TCR for 764: ['6bj3', '6bj8', '5xot']\n",
      "Closest TCR for 32447: ['7n5c', '7n4k', '3pqy', '7n5p']\n",
      "Closest TCR for 21442: ['6vma', '6vmc', '6vm9']\n",
      "Closest TCR for 30610: 5sws\n",
      "Closest TCR for 32401: 4mji\n",
      "Closest TCR for 32737: 8qfy\n",
      "Closest TCR for 33256: ['7n2r', '7n2p', '7n2q']\n",
      "Closest TCR for 21410: ['5jzi', '5yxn']\n",
      "Closest TCR for 33086: 5men\n",
      "Closest TCR for 32667: 1bd2\n",
      "Closest TCR for 32215: ['6vm7', '6vm8']\n",
      "Closest TCR for 1016: 4eup\n",
      "Closest TCR for 32382: 7byd\n",
      "Closest TCR for 32508: 4qrr\n",
      "Closest TCR for 33049: ['7nmg', '7nme', '7nmf']\n",
      "Closest TCR for 33050: 6uon\n",
      "Closest TCR for 21448: 7pbe\n",
      "Closest TCR for 31760: ['3mv8', '4prh', '3mv9', '3mv7', '4prp', '4pri']\n",
      "Closest TCR for 32036: 7phr\n",
      "Closest TCR for 32222: 8dnt\n",
      "Closest TCR for 32428: ['2gj6', '1qrn', '3pwp', '1qse', '3d3v', '3d39', '3qfj', '3h9s', '1ao7', '1qsf']\n",
      "Closest TCR for 30081: ['3vxu', '3w0w']\n",
      "Closest TCR for 33032: 3dxa\n",
      "Closest TCR for 33013: 4mji\n",
      "Closest TCR for 33237: 4eup\n",
      "Closest TCR for 1010: 6bj2\n",
      "Closest TCR for 32240: ['8dnt', '7pbe']\n",
      "Closest TCR for 1184: 4eup\n",
      "Closest TCR for 31990: 5isz\n",
      "Closest TCR for 29735: ['8gvb', '8gvi', '8gvg']\n",
      "Closest TCR for 32785: 5men\n",
      "Closest TCR for 33149: 6p64\n",
      "Closest TCR for 32350: 7q9b\n",
      "Closest TCR for 30079: ['3vxu', '3w0w']\n",
      "Closest TCR for 22561: 7n6e\n",
      "Closest TCR for 31994: 2nx5\n",
      "Closest TCR for 34506: ['4g9f', '4g8g']\n",
      "Closest TCR for 32098: 7phr\n",
      "Closest TCR for 32255: ['7nmg', '7nme', '7nmf']\n",
      "Closest TCR for 32841: ['5nmg', '5nme']\n",
      "Closest TCR for 32139: 7phr\n",
      "Closest TCR for 33318: ['3qdj', '6d78', '3qdg', '6am5', '6amu', '4l3e', '5c0b']\n",
      "Closest TCR for 32774: ['6ulr', '5hyj']\n",
      "Closest TCR for 1276: ['7rtr', '7n1f', '8qfy']\n",
      "Closest TCR for 32980: ['8eo8', '8enh', '8en8']\n",
      "Closest TCR for 33075: ['7ndq', '7ndu']\n",
      "Closest TCR for 32061: 5d2n\n",
      "Closest TCR for 32182: 5wlg\n",
      "Closest TCR for 32525: 6vrm\n",
      "Closest TCR for 32431: 3ffc\n",
      "Closest TCR for 31333: ['1nam', '2ol3', '1fo0']\n",
      "Closest TCR for 520: ['3kps', '3kpr', '1mi5']\n",
      "Closest TCR for 32532: 3sjv\n",
      "Closest TCR for 33158: 8f5a\n",
      "Closest TCR for 1648: 8gvi\n",
      "Closest TCR for 29719: 6uon\n",
      "Closest TCR for 32088: 6mtm\n",
      "Closest TCR for 33243: ['7nmg', '7nme', '7nmf']\n",
      "Closest TCR for 5: ['8gvb', '8gvi', '8gvg']\n",
      "Closest TCR for 31004: 3dxa\n",
      "Closest TCR for 72: ['2nx5', '8i5c']\n",
      "Closest TCR for 21372: 6uln\n",
      "Closest TCR for 32907: ['4jrx', '3kxf', '2ak4']\n",
      "Closest TCR for 183: 5yxu\n",
      "Closest TCR for 32766: 8qfy\n",
      "Closest TCR for 30576: 3tjh\n",
      "Closest TCR for 32977: 5jhd\n",
      "Closest TCR for 32786: 5tez\n",
      "Closest TCR for 32149: 6rp9\n",
      "Closest TCR for 20861: ['7n2r', '7n2p', '7n2q']\n",
      "Closest TCR for 32159: 6p64\n",
      "Closest TCR for 32482: 5men\n",
      "Closest TCR for 32214: 6uln\n",
      "Closest TCR for 22626: 6p64\n",
      "Closest TCR for 32987: 6vmx\n",
      "Closest TCR for 31726: 7phr\n",
      "Closest TCR for 1011: ['5nht', '5nqk']\n",
      "Closest TCR for 32340: 7n6e\n",
      "Closest TCR for 1072: ['3vxr', '3vxs']\n",
      "Closest TCR for 30556: 4qrp\n",
      "Closest TCR for 32357: ['7ndt', '2esv']\n",
      "Closest TCR for 32592: 5d2n\n",
      "Closest TCR for 723: 5e6i\n",
      "Closest TCR for 32091: 6p64\n",
      "Closest TCR for 32090: ['8gon', '8gom']\n",
      "Closest TCR for 32811: 3tjh\n",
      "Closest TCR for 21390: ['5jzi', '5yxn', '5yxu']\n",
      "Closest TCR for 32367: 3dxa\n",
      "Closest TCR for 31774: ['8eo8', '8enh', '8en8']\n",
      "Closest TCR for 32449: ['1kj2', '6rpa']\n",
      "Closest TCR for 1161: 6bj2\n",
      "Closest TCR for 31736: 4ftv\n",
      "Closest TCR for 32486: ['5jzi', '5yxn']\n",
      "Closest TCR for 21463: ['3qdj', '3qdg', '6am5', '6amu']\n",
      "Closest TCR for 32210: 5d2l\n",
      "Closest TCR for 1190: ['6ulr', '6uln', '5hyj']\n",
      "Closest TCR for 31791: ['7dzn', '7dzm']\n",
      "Closest TCR for 32299: ['6avf', '6tro']\n",
      "Closest TCR for 32686: 4eup\n",
      "Closest TCR for 32146: ['3qdj', '6d78', '3qdg', '6am5', '6amu', '4l3e', '5c0b']\n",
      "Closest TCR for 32584: 6avg\n",
      "Closest TCR for 2685: 2nx5\n",
      "Closest TCR for 29733: 6p64\n",
      "Closest TCR for 53: 3o4l\n",
      "Closest TCR for 30998: 3tjh\n",
      "Closest TCR for 21367: 6vrm\n",
      "Closest TCR for 33341: 5yxu\n",
      "Closest TCR for 32862: 4eup\n",
      "Closest TCR for 32436: 6p64\n",
      "Closest TCR for 32421: 3sjv\n",
      "Closest TCR for 31752: 7byd\n",
      "Closest TCR for 30210: ['7n5c', '7n4k', '3pqy', '7n5p']\n",
      "Closest TCR for 31748: 2ypl\n",
      "Closest TCR for 32259: 8qfy\n",
      "Closest TCR for 30992: ['7n2r', '7n2p', '7n2q']\n",
      "Closest TCR for 32724: 6uon\n",
      "Closest TCR for 32680: 2nx5\n",
      "Closest TCR for 31852: 1bd2\n",
      "Closest TCR for 32869: ['6ulr', '5hyj']\n",
      "Closest TCR for 32725: 4eup\n",
      "Closest TCR for 31786: ['3qdm', '3qeq']\n",
      "Closest TCR for 31947: 6l9l\n",
      "Closest TCR for 33064: 6rp9\n",
      "Closest TCR for 32316: 1bd2\n",
      "Closest TCR for 32777: ['5nmg', '5nme']\n",
      "Closest TCR for 32985: ['3kps', '3kpr', '1mi5']\n",
      "Closest TCR for 33095: 6rpa\n",
      "Closest TCR for 21652: ['6vma', '6vmc', '6vm9']\n",
      "Closest TCR for 32576: ['7n2r', '7n2p', '7n2q']\n",
      "Closest TCR for 31859: ['2uwe', '2jcc', '2j8u', '1lp9']\n",
      "Closest TCR for 28807: ['3kxf', '2ak4']\n",
      "Closest TCR for 32897: 3gsn\n",
      "Closest TCR for 29728: 8dnt\n",
      "Closest TCR for 32346: ['8gvb', '8gvi', '8gvg']\n",
      "Closest TCR for 32418: 3gsn\n",
      "Closest TCR for 1932: 5tez\n",
      "Closest TCR for 32716: ['4g9f', '4g8g']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "dataframe=pd.read_csv(\"./structures_annotation/TCRdist_df.csv\")\n",
    "common_df=pd.read_csv(\"./seqs_info/seqs_test_groups.csv\")\n",
    "\n",
    "# Open the file once outside the loop\n",
    "file_path = \"./seqs_info/closest_tcr.csv\"\n",
    "\n",
    "# Leer el archivo existente para verificar duplicados\n",
    "existing_tcrs = set()\n",
    "if os.path.exists(file_path):\n",
    "    with open(file_path, \"r\") as f:\n",
    "        # Leer el contenido y almacenar los TCR_names existentes en un conjunto\n",
    "        for line in f:\n",
    "            if line.startswith(\"tcr_name\"):\n",
    "                continue  # Saltar el encabezado\n",
    "            tcr_name_existing = line.split(\",\")[0]  # Obtener el tcr_name de cada línea\n",
    "            existing_tcrs.add(tcr_name_existing)\n",
    "\n",
    "# Abrir el archivo para escribir\n",
    "with open(file_path, \"a\") as f:\n",
    "    # Escribir encabezados si el archivo está vacío\n",
    "    if os.stat(file_path).st_size == 0:\n",
    "        f.write(\"tcr_name,closest_tcr\\n\")\n",
    "    \n",
    "    # Iterar a través de las filas del DataFrame\n",
    "    for _, row_data in common_df.iterrows():\n",
    "        alpha_seq = row_data['TRA_aa']\n",
    "        beta_seq = row_data['TRB_aa']\n",
    "        tcr_name = row_data['TCR_name']\n",
    "        \n",
    "        # Verificar si el TCR ya existe en el archivo\n",
    "        if int(tcr_name) in existing_tcrs:\n",
    "            print(f\"Skipping {tcr_name}, already exists in closest_tcr.csv.\")\n",
    "            continue\n",
    "        \n",
    "        # Encontrar el TCR más cercano\n",
    "        closest_tcr = find_closest_tcr(dataframe, alpha_seq, beta_seq, tcr_name)\n",
    "        \n",
    "        # Escribir el resultado en el CSV\n",
    "        f.write(f\"{tcr_name},{closest_tcr}\\n\")\n",
    "        \n",
    "        # Opcionalmente imprimir el resultado para confirmación\n",
    "        print(f\"Closest TCR for {tcr_name}: {closest_tcr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20426,6p64 (last row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find similar TCR for structural data (pdb_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './input/sequences_similar_allinfo.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Load the dataframes\u001b[39;00m\n\u001b[1;32m      9\u001b[0m dataframe \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./structures_annotation/TCRdist_df.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m pdb_common \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./input/sequences_similar_allinfo.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Initialize a list to collect errors\u001b[39;00m\n\u001b[1;32m     13\u001b[0m error_list \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/opt/miniconda3/envs/anarci/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/anarci/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/miniconda3/envs/anarci/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/anarci/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/miniconda3/envs/anarci/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './input/sequences_similar_allinfo.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load the dataframes\n",
    "dataframe = pd.read_csv(\"./structures_annotation/TCRdist_df.csv\")\n",
    "pdb_common = pd.read_csv(\"./input/sequences_similar_allinfo.csv\")\n",
    "\n",
    "# Initialize a list to collect errors\n",
    "error_list = []\n",
    "\n",
    "# Load the output file if it already exists, otherwise create an empty DataFrame\n",
    "output_file = \"./structures_annotation/closest_tcr_sequences.csv\"\n",
    "if os.path.exists(output_file) and os.stat(output_file).st_size > 0:\n",
    "    processed_df = pd.read_csv(output_file)\n",
    "    processed_tcr_names = set(processed_df['tcr_name'])  # Set of already processed TCR names\n",
    "else:\n",
    "    processed_tcr_names = set()\n",
    "\n",
    "# Open the output file in append mode\n",
    "with open(output_file, \"a\") as f:\n",
    "    # Write headers if the file is empty\n",
    "    if os.stat(output_file).st_size == 0:\n",
    "        f.write(\"tcr_name,closest_tcr\\n\")\n",
    "    \n",
    "    # Iterate through rows of the pdb_common DataFrame\n",
    "    for _, row_data in pdb_common.iterrows():\n",
    "        tcr_name = row_data['tcr_id']\n",
    "\n",
    "        # Skip processing if the tcr_name is already in the output file\n",
    "        if tcr_name in processed_tcr_names:\n",
    "            print(f\"Skipping {tcr_name}, already processed.\")\n",
    "            continue\n",
    "        \n",
    "        alpha_seq = row_data['alpha_seq']\n",
    "        beta_seq = row_data['beta_seq']\n",
    "        \n",
    "        try:\n",
    "            # Find the closest TCR\n",
    "            closest_tcr = find_closest_tcr(dataframe, alpha_seq, beta_seq, tcr_name)\n",
    "            \n",
    "            # Write the result to the CSV\n",
    "            f.write(f\"{tcr_name},{closest_tcr}\\n\")\n",
    "            \n",
    "            # Optionally print the result for confirmation\n",
    "            print(f\"Closest TCR for {tcr_name}: {closest_tcr}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            # Log the error and the corresponding TCR name\n",
    "            error_message = f\"Error processing {tcr_name}: {str(e)}\"\n",
    "            error_list.append(error_message)\n",
    "            print(error_message)  # Optionally print the error\n",
    "\n",
    "# At the end of processing, print or log the errors if needed\n",
    "if error_list:\n",
    "    print(\"\\nErrors encountered:\")\n",
    "    for error in error_list:\n",
    "        print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QPVQSPQAVILREGEDAIINCSSSKALYSVHWYRQKHGEAPIFLMILLKGGEQKGHDKISASFNEKKQQSSLYLTASQLSYSGTYFCGLGDAGNMLTFGGGTRLMVKPHIQNPDPAVYQLRDSKSSDKSVCLFTDFDSQTNVSQSKDSDVYITDKCVLDMRSMDFKSNSAVAWSNKSDFACANAFNNSIIPEDTFFPS AGVAQSPRYKIIEKRQSVAFWCNPISGHATLYWYQQILGQGPKLLIQFQNNGVVDDSQLPKDRFSAERLKGVDSTLKIQPAKLEDSAVYLCASSLGQGLLYGYTFGSGTRLTVLEDLNKVFPPEVAVFEPSEAEISHTQKATLVCLATGFYPDHVELSWWVNGKEVHSGVCTDPQPLKEQPALNDSRYALSSRLRVSATFWQNPRNHFRCQVQFYGLSENDEWTQDRAKPVTQIVSAEAWGRAD GTSGSPIVNR\n",
      "5wkf ASSLGQGLLYGYT TRBV11-2*01 TRBJ1-2*01 GLGDAGNMLT TRAV30*05 TRAJ39*01\n"
     ]
    }
   ],
   "source": [
    "dataframe=pd.read_csv(\"./structures_annotation/TCRdist_df.csv\")\n",
    "common_df=pd.read_csv(\"./structures_annotation/tcr_common.csv\")\n",
    "\n",
    "pdb_path=\"./pdb_files/5wkf.pdb\"\n",
    "pdb_id=pdb_path.split(\"/\")[-1].split(\".\")[0]\n",
    "alpha_seq, beta_seq, epitope = extract_specific_sequences(pdb_path, seq_dict)\n",
    "print(alpha_seq,beta_seq,epitope)\n",
    "tcr_id=pdb_id\n",
    "trab, traj = get_germlines(alpha_seq)\n",
    "trbv, trvj = get_germlines(beta_seq)\n",
    "cdr3a, _ = parse_CDR3(run_anarci(alpha_seq, \"D\"))\n",
    "cdr3b, _ = parse_CDR3(run_anarci(beta_seq, \"E\"))\n",
    "\n",
    "print(pdb_id,cdr3b,trbv,trvj,cdr3a,trab,traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe=pd.read_csv(\"./structures_annotation/TCRdist_df.csv\")\n",
    "closest_tcr = find_closest_tcr(dataframe, alpha_seq, beta_seq, tcr_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIND SIMILAR MHCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closest TCR for 2ckb: ['1g6r']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 61\u001b[0m\n\u001b[1;32m     59\u001b[0m pdb_file_path2 \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./pdb_files\u001b[39m\u001b[38;5;124m\"\u001b[39m, pdb_file2)\n\u001b[1;32m     60\u001b[0m chains2 \u001b[38;5;241m=\u001b[39m chain_dict\u001b[38;5;241m.\u001b[39mget(pdb_id2, {})\n\u001b[0;32m---> 61\u001b[0m seq_pdb2 \u001b[38;5;241m=\u001b[39m \u001b[43mextract_sequences\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdb_file_path2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# Perform global alignment between sequences\u001b[39;00m\n\u001b[1;32m     64\u001b[0m aligned_seq_pdb, aligned_seq_query, score \u001b[38;5;241m=\u001b[39m global_alignment(\n\u001b[1;32m     65\u001b[0m     seq_pdb1[chains1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmhc_chain\u001b[39m\u001b[38;5;124m'\u001b[39m]], \n\u001b[1;32m     66\u001b[0m     seq_pdb2[chains2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmhc_chain\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m     67\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/BSC/immuno_project/TCRranker/mapping.py:43\u001b[0m, in \u001b[0;36mextract_sequences\u001b[0;34m(pdb_file)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;124;03mExtract sequences for all chains from a PDB file.\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;124;03m    dict: Dictionary with chain IDs as keys and sequences as values.\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     42\u001b[0m parser \u001b[38;5;241m=\u001b[39m PDB\u001b[38;5;241m.\u001b[39mPDBParser(QUIET\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 43\u001b[0m structure \u001b[38;5;241m=\u001b[39m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstructure\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpdb_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m sequences \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m structure:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/anarci/lib/python3.12/site-packages/Bio/PDB/PDBParser.py:100\u001b[0m, in \u001b[0;36mPDBParser.get_structure\u001b[0;34m(self, id, file)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lines:\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmpty file.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 100\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlines\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstructure_builder\u001b[38;5;241m.\u001b[39mset_header(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheader)\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m# Return the Structure instance\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/anarci/lib/python3.12/site-packages/Bio/PDB/PDBParser.py:123\u001b[0m, in \u001b[0;36mPDBParser._parse\u001b[0;34m(self, header_coords_trailer)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheader, coords_trailer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_header(header_coords_trailer)\n\u001b[1;32m    122\u001b[0m \u001b[38;5;66;03m# Parse the atomic data; return the PDB file trailer\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrailer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_coordinates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoords_trailer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/anarci/lib/python3.12/site-packages/Bio/PDB/PDBParser.py:299\u001b[0m, in \u001b[0;36mPDBParser._parse_coordinates\u001b[0;34m(self, coords_trailer)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_pqr:\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;66;03m# init atom with pdb fields\u001b[39;00m\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 299\u001b[0m         \u001b[43mstructure_builder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_atom\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m            \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcoord\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbfactor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m            \u001b[49m\u001b[43moccupancy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m            \u001b[49m\u001b[43maltloc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfullname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m            \u001b[49m\u001b[43mserial_number\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m            \u001b[49m\u001b[43melement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m PDBConstructionException \u001b[38;5;28;01mas\u001b[39;00m message:\n\u001b[1;32m    310\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_PDB_exception(message, global_line_counter)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/anarci/lib/python3.12/site-packages/Bio/PDB/StructureBuilder.py:231\u001b[0m, in \u001b[0;36mStructureBuilder.init_atom\u001b[0;34m(self, name, coord, b_factor, occupancy, altloc, fullname, serial_number, element, pqr_charge, radius, is_pqr)\u001b[0m\n\u001b[1;32m    225\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    226\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAtom names \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m differ only in spaces at line \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    227\u001b[0m             \u001b[38;5;241m%\u001b[39m (duplicate_fullname, fullname, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mline_counter),\n\u001b[1;32m    228\u001b[0m             PDBConstructionWarning,\n\u001b[1;32m    229\u001b[0m         )\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_pqr:\n\u001b[0;32m--> 231\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39matom \u001b[38;5;241m=\u001b[39m \u001b[43mAtom\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoord\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mb_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m        \u001b[49m\u001b[43moccupancy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43maltloc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfullname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserial_number\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43melement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_pqr:\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39matom \u001b[38;5;241m=\u001b[39m Atom(\n\u001b[1;32m    243\u001b[0m         name,\n\u001b[1;32m    244\u001b[0m         coord,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    252\u001b[0m         radius,\n\u001b[1;32m    253\u001b[0m     )\n",
      "File \u001b[0;32m/opt/miniconda3/envs/anarci/lib/python3.12/site-packages/Bio/PDB/Atom.py:34\u001b[0m, in \u001b[0;36mAtom.__init__\u001b[0;34m(self, name, coord, bfactor, occupancy, altloc, fullname, serial_number, element, pqr_charge, radius)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mAtom\u001b[39;00m:\n\u001b[1;32m     23\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Define Atom class.\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \n\u001b[1;32m     25\u001b[0m \u001b[38;5;124;03m    The Atom object stores atom name (both with and without spaces),\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m    atomic charge and radius.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     35\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     36\u001b[0m         name,\n\u001b[1;32m     37\u001b[0m         coord,\n\u001b[1;32m     38\u001b[0m         bfactor,\n\u001b[1;32m     39\u001b[0m         occupancy,\n\u001b[1;32m     40\u001b[0m         altloc,\n\u001b[1;32m     41\u001b[0m         fullname,\n\u001b[1;32m     42\u001b[0m         serial_number,\n\u001b[1;32m     43\u001b[0m         element\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     44\u001b[0m         pqr_charge\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     45\u001b[0m         radius\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     46\u001b[0m     ):\n\u001b[1;32m     47\u001b[0m \u001b[38;5;250m        \u001b[39m\u001b[38;5;124;03m\"\"\"Initialize Atom object.\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m        :param name: atom name (eg. \"CA\"). Note that spaces are normally stripped.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;124;03m        :type radius: number\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;124;03m        \"\"\"\u001b[39;00m\n\u001b[1;32m     77\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlevel \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "general_df = pd.read_csv('./structures_annotation/general.txt', sep='\\t')\n",
    "chain_dict = {}\n",
    "for pdb_id, group in general_df.groupby('pdb.id'):\n",
    "    chains = {\n",
    "        'tcra_chain': None,\n",
    "        'tcrb_chain': None,\n",
    "        'peptide_chain': None,\n",
    "        'mhc_chain': None\n",
    "    }\n",
    "    \n",
    "    for _, row in group.iterrows():\n",
    "        if row['chain.component'] == 'TCR' and row['chain.type'] == 'TRA':\n",
    "            chains['tcra_chain'] = row['chain.id']\n",
    "        elif row['chain.component'] == 'TCR' and row['chain.type'] == 'TRB':\n",
    "            chains['tcrb_chain'] = row['chain.id']\n",
    "        elif row['chain.component'] == 'PEPTIDE':\n",
    "            chains['peptide_chain'] = row['chain.id']\n",
    "        elif row['chain.component'] == 'MHC' and row['chain.type'] == 'MHCa':\n",
    "            chains['mhc_chain'] = row['chain.id']\n",
    "        \n",
    "    chain_dict[pdb_id] = chains\n",
    "\n",
    "# Initialize output file\n",
    "output_file = \"./closest_mhc_results.csv\"\n",
    "if os.path.exists(output_file) and os.stat(output_file).st_size > 0:\n",
    "    processed_df = pd.read_csv(output_file)\n",
    "    processed_pdb_ids = set(processed_df['pdb_id'])  # Set of already processed PDB IDs\n",
    "else:\n",
    "    processed_pdb_ids = set()\n",
    "\n",
    "# Open output CSV file in append mode\n",
    "with open(output_file, mode=\"a\", newline=\"\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "\n",
    "    # Write header only if the file is empty\n",
    "    if os.stat(output_file).st_size == 0:\n",
    "        writer.writerow([\"pdb_id\", \"closest_mhc\"])  # Write header\n",
    "\n",
    "    # Iterate through each PDB file in pdb_nr\n",
    "    for pdb_file1 in os.listdir(\"./pdb_nr\"):\n",
    "        if pdb_file1.endswith(\".pdb\"):\n",
    "            pdb_id1 = pdb_file1.split(\".\")[0]\n",
    "\n",
    "            # Skip processing if PDB is already processed\n",
    "            if pdb_id1 in processed_pdb_ids:\n",
    "                continue\n",
    "            \n",
    "            scores = {}  # Initialize dictionary to store scores for each pdb_file1\n",
    "            pdb_file_path1 = os.path.join(\"./pdb_nr\", pdb_file1)\n",
    "            chains1 = chain_dict.get(pdb_id1, {})\n",
    "            seq_pdb1 = extract_sequences(pdb_file_path1)\n",
    "            \n",
    "            for pdb_file2 in os.listdir(\"./pdb_files\"):\n",
    "                if pdb_file2.endswith(\".pdb\") and pdb_file2 != pdb_file1:\n",
    "                    pdb_id2 = pdb_file2.split(\".\")[0]\n",
    "                    pdb_file_path2 = os.path.join(\"./pdb_files\", pdb_file2)\n",
    "                    chains2 = chain_dict.get(pdb_id2, {})\n",
    "                    seq_pdb2 = extract_sequences(pdb_file_path2)\n",
    "\n",
    "                    # Perform global alignment between sequences\n",
    "                    aligned_seq_pdb, aligned_seq_query, score = global_alignment(\n",
    "                        seq_pdb1[chains1['mhc_chain']], \n",
    "                        seq_pdb2[chains2['mhc_chain']]\n",
    "                    )\n",
    "                    \n",
    "                    # Store the score in the dictionary\n",
    "                    scores[pdb_id2] = score\n",
    "\n",
    "            # Find the best match with the highest score\n",
    "            max_score = max(scores.values())\n",
    "            max_pdb_ids = [pdb_id for pdb_id, score in scores.items() if score == max_score]\n",
    "\n",
    "            # Format closest_mhc as a Python list with single quotes\n",
    "            closest_mhc_list = \"['\" + \"', '\".join(max_pdb_ids) + \"']\"\n",
    "\n",
    "            # Print only the closest TCR in the desired format\n",
    "            print(f\"Closest MHC for {pdb_id1}: {closest_mhc_list}\")\n",
    "\n",
    "            # Write the results to the CSV file\n",
    "            writer.writerow([pdb_id1, closest_mhc_list])\n",
    "\n",
    "print(\"Processing complete. Results saved to closest_mhc_results.csv.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "#Sequence df\n",
    "# df=pd.read_csv(\"./structures_annotation/X.csv\")\n",
    "\n",
    "# Open a CSV file to write the results\n",
    "with open(\"closest_mhc_results.csv\", mode=\"w\", newline=\"\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow([\"pdb_id\", \"closest_mhc\"])  # Write the header row\n",
    "\n",
    "    for _, row_data in df.iterrows():\n",
    "        scores={}\n",
    "        tcr_name = row_data['tcr_id']\n",
    "        mch_seq = row_data['mhc_seq']\n",
    "\n",
    "        print(f\"Processing TCR: {tcr_name}\")\n",
    "            \n",
    "        for pdb_file2 in os.listdir(\"./pdb_files\"):\n",
    "            if pdb_file2.endswith(\".pdb\"):\n",
    "                pdb_id2 = pdb_file2.split(\".\")[0]\n",
    "                pdb_file_path2 = os.path.join(\"./pdb_files\", pdb_file2)\n",
    "                chains2 = chain_dict.get(pdb_id2, {})\n",
    "                seq_pdb2 = extract_sequences(pdb_file_path2)\n",
    "\n",
    "                # Perform global alignment\n",
    "                aligned_seq_pdb, aligned_seq_query, score = global_alignment(mhc_seq, seq_pdb2[chains2['mhc_chain']])\n",
    "                    \n",
    "                # Store the score in the dictionary\n",
    "                scores[pdb_id2] = score\n",
    "                print(f\" Compared {tcr_id} with {pdb_id2}: Score = {score}\")\n",
    "\n",
    "            # Find the maximum score\n",
    "            max_score = max(scores.values())\n",
    "            max_pdb_ids = [pdb_id for pdb_id, score in scores.items() if score == max_score]\n",
    "\n",
    "            # Write the best match(es) to the CSV file\n",
    "            if len(max_pdb_ids) == 1:\n",
    "                closest_mhc = max_pdb_ids[0]\n",
    "                print(f\"For PDB {pdb_id1}, the best match is: {closest_mhc} with score {max_score}.\")\n",
    "            else:\n",
    "                closest_mhc = \", \".join(max_pdb_ids)\n",
    "                print(f\"For PDB {pdb_id1}, the best matches are: {closest_mhc} with score {max_score}.\")\n",
    "\n",
    "            # Write the results to the CSV file\n",
    "            writer.writerow([pdb_id1, closest_mhc])\n",
    "\n",
    "print(\"Processing complete. Results saved to closest_mhc_results.csv.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anarci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
